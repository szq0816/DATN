# DATN

The paper titled "**Dual Attention Transformer Network for Hyperspectral Image Classification**" 

## Pytorch
Torch: 1.13.1

Python: 3.9.16
 
## Model
Learning Rate: 0.008

Epoch: 100

Batch Size: 64

Patch Size: $11\times11$

Optimizer: Adam (weight_decay=1e-4)

Scheduler: LambdaLR


## Other

We encourage researchers to cite our latest work. 

We encourage researchers to achieve different comparative experiments (papers) within a code framework, to achieve a fair comparison.

If you encounter any problems reproducing the code, please do not hesitate to contact us.

E-mail: killlakill2023@gmail.com

